{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5472acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "from generic_agent import GenericAgent\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib\n",
    "from collections import deque, namedtuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6239febf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Name:  CartPole\n",
      "Action Space Type:  DISCRETE\n",
      "Observation Space Type:  CONTINUOUS\n",
      "Observation Space:  Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "env = Environment(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d0a835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device :  cpu\n"
     ]
    }
   ],
   "source": [
    "# Device Utility\n",
    "\n",
    "device = \"cpu\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd668b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\", \"terminate\"))\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity=10000):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86043742",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eefe20",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e7ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a146c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        \n",
    "        self.inp = nn.Linear(in_feature, 128)\n",
    "        self.dense1 = nn.Linear(128, 128)\n",
    "        self.out = nn.Linear(128, out_feature)\n",
    "    \n",
    "    def forward(self, observation):\n",
    "        \n",
    "        resp = nn.functional.relu(self.inp(observation))\n",
    "        resp = nn.functional.relu(self.dense1(resp))\n",
    "        return self.out(self.out(resp))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b871a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent(GenericAgent):\n",
    "    \n",
    "    def __init__(self, env, ep):\n",
    "        super(QAgent, self).__init__(env)\n",
    "        self.dqn = DQN(self.observation_size[0], self.action_size).to(device)\n",
    "        self.optim = optim.AdamW(self.dqn.parameters(), amsgrad=True)\n",
    "        self.criteria = nn.SmoothL1Loss()\n",
    "        self.steps_done = 0\n",
    "    \n",
    "    def get_action(self, observation):\n",
    "        \n",
    "        # Defining Exploration and exploration tradeoff\n",
    "        EPS_START, EPS_END, EPS_DECAY = 0.05, 0.9, 1000    \n",
    "        threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1 * self.steps_done/EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        \n",
    "        if np.random.random() > threshold:\n",
    "            action = self.get_random_action()\n",
    "            return torch.tensor(action, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            obs = torch.tensor([observation], dtype=torch.float32).to(device)\n",
    "            return self.dqn(obs).argmax()[0]\n",
    "    \n",
    "    def train_model():\n",
    "        \n",
    "        batch_data = memory.sample(BATCH_SIZE)\n",
    "        \n",
    "        batches = Transition(*zip(*batch_data))\n",
    "        \n",
    "            \n",
    "        # Non-Terminated States\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batches.next_state)), device=device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.tensor([x for x in batches.next_state if x is not None], device=device, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Preprocess records\n",
    "        states = torch.tensor(batches.state).view(-1, 1).to(device)\n",
    "        actions = torch.tensor(batches.action).view(-1, 1).to(device)\n",
    "        rewards = torch.tensor(batches.reward).view(-1, 1).to(device)\n",
    "\n",
    "        # Train Execution\n",
    "        pred_actions = self.dqn(states).gather(1, actions)\n",
    "\n",
    "\n",
    "        next_state_batch = torch.zeros((BATCH_SIZE)).to(device)\n",
    "        with torch.no_grad():\n",
    "            next_state_batch[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "        expected_state_action_values = (next_state_batch * GAMMA) + rewards\n",
    "\n",
    "\n",
    "        # Define Criteria \n",
    "        criteria = nn.SmoothL1Loss()\n",
    "        loss = criteria(pred_actions, expected_state_action_values)\n",
    "\n",
    "        # Optimization \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        nn.utils.clip_grad_norm(policy_net.parameters(), 100)\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c379216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb7e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
